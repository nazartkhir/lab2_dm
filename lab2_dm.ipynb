{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторна робота 2 \n",
    "Предмет: Дискретна математика\n",
    "Семестр: 2\n",
    "Виконавці: Бабенко Аліна, Тхір Назар.\n",
    "\n",
    "Розподіл роботи між учасниками команди:\n",
    "Алгоритм Гафмана - Бабенко Аліна\n",
    "LZ77 - Тхір Назар\n",
    "LZW - Бабенко Аліна"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нижче приведені алгоритми за порядком, їх перевірки та коефіцієнти стиску: LZ77, LZW , алгоритм Гафмана, Deflate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "class lz77:\n",
    "    def __init__(self, buffer_length=255) -> None:\n",
    "        \"\"\"\n",
    "        Init a lz77 class with a buffer length.\n",
    "        Default set to 255.\n",
    "        \"\"\"\n",
    "        self.buffer_length = buffer_length\n",
    "\n",
    "    def read(self, file_path):\n",
    "        \"\"\"\n",
    "        Read data from a file.\n",
    "        \"\"\"\n",
    "        with open(file_path, encoding=\"UTF-8\") as file:\n",
    "            self.data = file.read()\n",
    "            self.orig = copy.deepcopy(self.data)\n",
    "    \n",
    "    def write(self, data, file_path):\n",
    "        \"\"\"\n",
    "        Write data into a file.\n",
    "        \"\"\"\n",
    "        with open(file_path,'w', encoding=\"UTF-8\") as file:\n",
    "            file.write(data)\n",
    "\n",
    "    def find_substring(self, buffer, data):\n",
    "        \"\"\"\n",
    "        Find the longest common substring in the buffer.\n",
    "        \"\"\"\n",
    "        length = 0\n",
    "        offset = 0\n",
    "        while True:\n",
    "            it = buffer.find(data[:length + 1])\n",
    "            if it != -1:\n",
    "                offset = len(buffer[it:])\n",
    "                length += 1\n",
    "                if data[:length] == data[:length + 1]:\n",
    "                    return (length, (offset, length, None))\n",
    "                continue\n",
    "            break\n",
    "        next = data[length]\n",
    "        return (length, (offset, length, next))\n",
    "\n",
    "    def compress(self):\n",
    "        \"\"\"\n",
    "        Compress the data.\n",
    "        \"\"\"\n",
    "        ans = []\n",
    "        buffer = \"\"\n",
    "        while self.data:\n",
    "            length, code = self.find_substring(buffer, self.data)\n",
    "            buffer += self.data[:length + 1]\n",
    "            if len(buffer) > self.buffer_length:\n",
    "                buffer = buffer[len(buffer) - self.buffer_length:]\n",
    "            self.data = self.data[length + 1:]\n",
    "            ans.append(code)\n",
    "        self.compressed = ans\n",
    "\n",
    "    def decompress(self):\n",
    "        \"\"\"\n",
    "        Decompress the data.\n",
    "        \"\"\"\n",
    "        buffer = \"\"\n",
    "        ans = \"\"\n",
    "        for (offset, length, next) in self.compressed:\n",
    "            if next == None:\n",
    "                ans +=  buffer[len(buffer) - offset:len(buffer) - offset + length]\n",
    "                break\n",
    "            added = buffer[len(buffer) - offset:len(buffer) - offset + length] + next\n",
    "            ans += added\n",
    "            buffer += added\n",
    "            if len(buffer) > self.buffer_length:\n",
    "                buffer = buffer[len(buffer) - self.buffer_length:]\n",
    "        self.decompressed = ans\n",
    "\n",
    "        \n",
    "\n",
    "    def encode(self, file_path):\n",
    "        \"\"\"\n",
    "        Encode data from a file and write into the new file.\n",
    "        \"\"\"\n",
    "        self.read(file_path)\n",
    "        self.compress()\n",
    "        self.write(str(self.compressed),f\"{file_path.split('.')[0]}_compressed.txt\")\n",
    "\n",
    "    def decode(self, file_path):\n",
    "        \"\"\"\n",
    "        Decode a code from a file.\n",
    "        \"\"\"\n",
    "        self.decompress()\n",
    "        self.write(self.decompressed, f\"{file_path.split('.')[0]}_decompressed.txt\")\n",
    "\n",
    "    def calculate_compression(self):\n",
    "        \"\"\"\n",
    "        Calculate compression.\n",
    "        \"\"\"\n",
    "        new = len(self.compressed) * 3\n",
    "        orig = len(self.orig)\n",
    "        return new/orig\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate: 67.784%\n"
     ]
    }
   ],
   "source": [
    "lz = lz77()\n",
    "lz.encode('drive.txt')\n",
    "lz.decode('drive_compressed.txt')\n",
    "with open('drive.txt', encoding=\"UTF-8\") as file:\n",
    "            orig = file.read()\n",
    "with open('drive_compressed_decompressed.txt', encoding=\"UTF-8\") as file:\n",
    "            new = file.read()\n",
    "assert orig == new\n",
    "print(f'Compression rate: {round(lz.calculate_compression() * 100, 3)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Висновок: цей алгоритм варто використовувати коли неоюхідно закодувати дані, що повторюються(циклічні)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZW: \n",
    "    def read(self, file_path):\n",
    "        \"\"\"\n",
    "        Read data from a file.\n",
    "        \"\"\"\n",
    "        with open(file_path, encoding=\"UTF-8\") as file:\n",
    "            self.data = file.read()\n",
    "        \n",
    "    def write(self, data, file_path):\n",
    "        \"\"\"\n",
    "        Write data into a file.\n",
    "        \"\"\"\n",
    "        with open(file_path,'w', encoding=\"UTF-8\") as file:\n",
    "            file.write(data)\n",
    "    \n",
    "    def compress(self):\n",
    "        \"\"\"\n",
    "        Encode the data.\n",
    "        \"\"\"\n",
    "        dictionary = {chr(i): i for i in range(256)}\n",
    "        prev = \"\"\n",
    "        ans = []\n",
    "        for elem in self.data:\n",
    "            new = prev + elem\n",
    "            if new in dictionary:\n",
    "                prev = new\n",
    "            else:\n",
    "                ans.append(dictionary[prev])\n",
    "                dictionary[new] = len(dictionary)\n",
    "                prev = elem\n",
    "        if prev:\n",
    "            ans.append(dictionary[prev])\n",
    "        self.compressed = ans\n",
    "\n",
    "\n",
    "    def decompress(self):\n",
    "        \"\"\"\n",
    "        Decode the data.\n",
    "        \"\"\"\n",
    "        dictionary = {i: chr(i) for i in range(256)}\n",
    "        prev = chr(self.compressed[0])\n",
    "        ans = prev\n",
    "        for code in self.compressed[1:]:\n",
    "            if code in dictionary:\n",
    "                val = dictionary[code]\n",
    "            else:\n",
    "                val = prev + prev[0]\n",
    "            ans += val\n",
    "            dictionary[len(dictionary)] = prev + val[0]\n",
    "            prev = val\n",
    "        self.decompressed = ans\n",
    "\n",
    "    def encode(self, file_path):\n",
    "        \"\"\"\n",
    "        Encode data from a file and write into the new file.\n",
    "        \"\"\"\n",
    "        self.read(file_path)\n",
    "        self.compress()\n",
    "        self.write(str(self.compressed),f\"{file_path.split('.')[0]}_compressed.txt\")\n",
    "\n",
    "    def decode(self, file_path):\n",
    "        \"\"\"\n",
    "        Decode a code from a file.\n",
    "        \"\"\"\n",
    "        self.decompress()\n",
    "        self.write(self.decompressed, f\"{file_path.split('.')[0]}_decompressed.txt\")\n",
    "    \n",
    "    def calculate_compression(self):\n",
    "        \"\"\"\n",
    "        Calculate compression.\n",
    "        \"\"\"\n",
    "        new = len(self.compressed) * 2\n",
    "        orig = len(self.data)\n",
    "        return new/orig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate: 30.577%\n"
     ]
    }
   ],
   "source": [
    "lzw = LZW()\n",
    "lzw.encode('drive.txt')\n",
    "lzw.decode('drive_compressed.txt')\n",
    "with open('drive.txt', encoding=\"UTF-8\") as file:\n",
    "            orig = file.read()\n",
    "with open('drive_compressed_decompressed.txt', encoding=\"UTF-8\") as file:\n",
    "            new = file.read()\n",
    "assert orig == new\n",
    "print(f'Compression rate: {round(lzw.calculate_compression() * 100, 3)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Висновок:\n",
    "    Краще використовувати LZW, коли потрібно стиснути довгу послідовність символів. LZW ефективно працює з даними, які мають більш рівномірний розподіл частот символів, що дозволяє зберігати більше інформації в меншому обсязі."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \"\"\"\n",
    "    Huffman tree node.\n",
    "    \"\"\"\n",
    "    def __init__(self, character = None, freq = 0, left = None, right = None) -> None:\n",
    "        self.character = character\n",
    "        self.freq = freq\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "class HuffmanTree():\n",
    "    def __init__(self) -> None:\n",
    "        self.encoder = {}\n",
    "        self.decoder = {}\n",
    "    def read(self, file_path):\n",
    "        \"\"\"\n",
    "        Read data from a file.\n",
    "        \"\"\"\n",
    "        with open(file_path, encoding=\"UTF-8\") as file:\n",
    "            self.data = file.read()\n",
    "        self.build_tree()\n",
    "\n",
    "    def write(self, data, file_path):\n",
    "        \"\"\"\n",
    "        Write data into a file.\n",
    "        \"\"\"\n",
    "        with open(file_path,'w', encoding=\"UTF-8\") as file:\n",
    "            file.write(data)\n",
    "    \n",
    "    def build_tree(self):\n",
    "        \"\"\"\n",
    "        Build the Huffman tree from the given data.\n",
    "        \"\"\"\n",
    "        frequency = {}\n",
    "        for character in self.data:\n",
    "            frequency[character] = frequency.get(character, 0) + 1\n",
    "        sorted_freq = {k: v for k, v in sorted(frequency.items(), key=lambda item: item[1])}\n",
    "        vertexes = [Node(character=character, freq=freq) for character, freq in sorted_freq.items()]\n",
    "        while len(vertexes) > 1:\n",
    "            vertexes.sort(key=lambda x: x.freq)\n",
    "            right = vertexes.pop(0)\n",
    "            left = vertexes.pop(0)\n",
    "            parent_vert = Node(freq=left.freq + right.freq, left=left, right=right)\n",
    "            vertexes.append(parent_vert)\n",
    "        self.root = vertexes[0]\n",
    "        self.get_codes(self.root)\n",
    "\n",
    "    def get_codes(self, node, code=''):\n",
    "        \"\"\"\n",
    "        Make codes for each character.\n",
    "        \"\"\"\n",
    "        if node is None:\n",
    "            return\n",
    "        if node.character is not None:\n",
    "            node.code = code\n",
    "            self.encoder[node.character] = code\n",
    "            self.decoder[code] = node.character\n",
    "        self.get_codes(node.left, code + '0')\n",
    "        self.get_codes(node.right, code + '1')\n",
    "\n",
    "    def encode(self, file_path):\n",
    "        \"\"\"\n",
    "        Encode the given data using the Huffman tree.\n",
    "        \"\"\"\n",
    "        self.read(file_path)\n",
    "        ans = ''\n",
    "        for character in self.data:\n",
    "            ans += self.encoder[character]\n",
    "        self.coded = ans\n",
    "        self.write(str(self.coded),f\"{file_path.split('.')[0]}_compressed.txt\")\n",
    "\n",
    "    def decode(self, file_path):\n",
    "        \"\"\"\n",
    "        Decode the given data using the Huffman tree.\n",
    "        \"\"\"\n",
    "        ans = ''\n",
    "        cur = ''\n",
    "        for elem in self.coded:\n",
    "            cur += elem\n",
    "            if cur in self.decoder:\n",
    "                ans += self.decoder[cur]\n",
    "                cur = ''\n",
    "        self.decoded = ans\n",
    "        self.write(str(self.decoded),f\"{file_path.split('.')[0]}_decompressed.txt\")\n",
    "    \n",
    "    def calculate_compression(self):\n",
    "        \"\"\"\n",
    "        Calculate compression.\n",
    "        \"\"\"\n",
    "        new = int(len(self.coded) / 8)\n",
    "        orig = len(self.data)\n",
    "        return new/orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate: 43.923%\n"
     ]
    }
   ],
   "source": [
    "huf = HuffmanTree()\n",
    "huf.encode('drive.txt')\n",
    "huf.decode('drive_compressed.txt')\n",
    "with open('drive.txt', encoding=\"UTF-8\") as file:\n",
    "            orig = file.read()\n",
    "with open('drive_compressed_decompressed.txt', encoding=\"UTF-8\") as file:\n",
    "            new = file.read()\n",
    "assert orig == new\n",
    "print(f'Compression rate: {round(huf.calculate_compression() * 100, 3)}%')\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Висновок: \n",
    "    Краще використовувати кодування Гафмана, коли необхідно стиснути дані, щоб зменшити їх розмір. Кодування Гафмана дає кращі результати при використанні для стиснення даних, що мають велику кількість повторюваних символів."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deflate:\n",
    "    def __init__(self):\n",
    "        self.lz = lz77()\n",
    "        self.huf = HuffmanTree()\n",
    "    def read(self, file_path):\n",
    "        \"\"\"\n",
    "        Read data from a file.\n",
    "        \"\"\"\n",
    "        with open(file_path, encoding=\"UTF-8\") as file:\n",
    "            self.data = file.read()\n",
    "        \n",
    "    def write(self, data, file_path):\n",
    "        \"\"\"\n",
    "        Write data into a file.\n",
    "        \"\"\"\n",
    "        with open(file_path,'w', encoding=\"UTF-8\") as file:\n",
    "            file.write(data)\n",
    "    \n",
    "    def encode(self, file_path):\n",
    "        \"\"\"\n",
    "        Encode the data.\n",
    "        \"\"\"\n",
    "        self.lz.encode(file_path)     \n",
    "        self.huf.encode(f'{file_path.split(\".\")[0]}_compressed.txt') \n",
    "        self.write(self.huf.coded, f'{file_path.split(\".\")[0]}_compressed_deflated.txt')\n",
    "\n",
    "    def decode(self, file_path_in, file_path_out):\n",
    "        \"\"\"\n",
    "        Decode the data.\n",
    "        \"\"\"\n",
    "        data = self.read(file_path_in)\n",
    "        huf.decoded = data\n",
    "        huf.decode(file_path_in)\n",
    "        self.lz.decompressed = self.read(f'{file_path_in.split(\".\")[0]}_decompressed.txt')\n",
    "        self.lz.decode(file_path_out)\n",
    "    \n",
    "    def calculate_compression(self):\n",
    "        return self.lz.calculate_compression() * self.huf.calculate_compression()\n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression rate: 31.374%\n"
     ]
    }
   ],
   "source": [
    "defl = Deflate()\n",
    "defl.encode('drive.txt')\n",
    "defl.decode('drive_compressed_deflated.txt','inflated.txt')\n",
    "with open('drive.txt', encoding=\"UTF-8\") as file:\n",
    "            orig = file.read()\n",
    "with open('inflated_decompressed.txt', encoding=\"UTF-8\") as file:\n",
    "            new = file.read()\n",
    "assert orig == new\n",
    "print(f'Compression rate: {round(defl.calculate_compression() * 100, 3)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замість того щоб будувати графіки (потрібно багато даних та час) ми вирішили навести статистику:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lz77 small compression rate: 67.784%\n",
      "Lz77 big compression rate: 87.753%\n",
      "Lz77 cyclic compression rate: 2.069%\n",
      "LZW small compression rate: 30.577%\n",
      "LZW big compression rate: 16.729%\n",
      "LZW cyclic compression rate: 11.737%\n",
      "Huffman small compression rate: 43.923%\n",
      "Huffman big compression rate: 52.844%\n",
      "Huffman cyclic compression rate: 53.931%\n",
      "Deflate small compression rate: 31.374%\n",
      "Deflate big compression rate: 40.336%\n",
      "Deflate cyclic compression rate: 0.936%\n"
     ]
    }
   ],
   "source": [
    "lz = lz77()\n",
    "lz.encode('drive.txt')\n",
    "print(f'Lz77 small compression rate: {round(lz.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "lz = lz77()\n",
    "lz.encode('2mb.txt')\n",
    "print(f'Lz77 big compression rate: {round(lz.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "lz = lz77()\n",
    "lz.encode('cyclic.txt')\n",
    "print(f'Lz77 cyclic compression rate: {round(lz.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "lzw = LZW()\n",
    "lzw.encode('drive.txt')\n",
    "print(f'LZW small compression rate: {round(lzw.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "lzw = LZW()\n",
    "lzw.encode('2mb.txt')\n",
    "print(f'LZW big compression rate: {round(lzw.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "lzw = LZW()\n",
    "lzw.encode('cyclic.txt')\n",
    "print(f'LZW cyclic compression rate: {round(lzw.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "huf = HuffmanTree()\n",
    "huf.encode('drive.txt')\n",
    "print(f'Huffman small compression rate: {round(huf.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "huf = HuffmanTree()\n",
    "huf.encode('2mb.txt')\n",
    "print(f'Huffman big compression rate: {round(huf.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "huf = HuffmanTree()\n",
    "huf.encode('cyclic.txt')\n",
    "print(f'Huffman cyclic compression rate: {round(huf.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "defl = Deflate()\n",
    "defl.encode('drive.txt')\n",
    "print(f'Deflate small compression rate: {round(defl.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "defl = Deflate()\n",
    "defl.encode('2mb.txt')\n",
    "print(f'Deflate big compression rate: {round(defl.calculate_compression() * 100, 3)}%')\n",
    "\n",
    "defl = Deflate()\n",
    "defl.encode('cyclic.txt')\n",
    "print(f'Deflate cyclic compression rate: {round(defl.calculate_compression() * 100, 3)}%')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чітко видно сильні та слабкі сторони кожного з алгоритмів."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
